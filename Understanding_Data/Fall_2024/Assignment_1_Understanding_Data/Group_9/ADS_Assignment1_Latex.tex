\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{ADS\_Assignment1}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \begin{center}
    \Large\textbf{IMAGE DATA}
    \end{center}

     
\section*{\Large\underline{\textbf{Title and Research Question}}}\label{references}


\begin{itemize}
    \item \textbf{Title} 
    
    Image Data Processing and Its Role in Machine Learning: A Case Study in Bone Fracture Detection

    \item \textbf{Research Question}
    
    This chapter investigates the critical role of image data preprocessing
    in enhancing the performance of machine learning models, particularly
    focusing on complex computer vision tasks such as facial recognition and
    medical imaging diagnostics. Specifically, we explore the use of image
    data processing techniques in the context of bone fracture detection
    using X-ray images.

    \item \textbf{Interest and Relevance} 
    
    Image data forms the cornerstone of numerous advanced applications in
    both commercial and research domains. With the advent of high-resolution
    imaging technologies and the proliferation of image-centric social media, the ability to efficiently and accurately process image data is more crucial than ever. In healthcare, accurate and efficient image data processing has the potential to save lives by enabling quicker and more reliable diagnoses. Bone fractures are common injuries, and timely diagnosis is crucial for effective treatment. Traditionally, radiologists analyze X-rays manually, which is time-consuming and prone to human error. Deep learning models, such as Convolutional Neural Networks (CNNs), can significantly enhance the speed and accuracy of fracture detection, making this topic both relevant and impactful. 
    
    With advances in deep learning, particularly in the field of computer vision, automated methods for analyzing medical images have gained traction. The ability to accurately detect bone fractures not only reduces the workload on healthcare professionals but also minimizes the risks associated with delayed or incorrect diagnoses.
\end{itemize}

\begin{itemize}
\item\textbf{ Theoretical Background}\label{theoretical-background}

The theory behind image data processing is rooted in signal processing
and pattern recognition. Modern methodologies have evolved from basic
filtering techniques to sophisticated machine learning models that can
learn optimal features and tasks from the data itself, revolutionizing
how computers interpret complex visual inputs. This transition underpins
the development of algorithms that can handle high-dimensional data and
perform tasks ranging from object detection to real-time video analysis.
\end{itemize}

\section*{\Large\underline{\textbf{Theory and Background}}}\label{references}

\begin{itemize}
\item\textbf{Theoretical Foundation}\label{theoretical-foundation} 

The theory behind image data processing is rooted in signal processing
and pattern recognition. Modern methodologies have evolved from basic
filtering techniques to sophisticated machine learning models that can
learn optimal features from the data itself, revolutionizing how
computers interpret complex visual inputs. This transition underpins the
development of algorithms that can handle high-dimensional data and
perform tasks ranging from object detection to real-time video analysis.

Image data processing initially relied on manual techniques such as
basic thresholding and filtering to enhance or extract visual features.
However, the advent of machine learning and deep learning has introduced
more sophisticated methods, where models automatically learn relevant
features from data, significantly enhancing accuracy and reducing the
need for manual intervention.

Convolutional Neural Networks (CNNs) have emerged as a key tool in
processing and analyzing image data, particularly in medical
diagnostics. CNNs utilize convolutional layers to extract important
features from image data, such as edges, textures, and gradients,
allowing them to handle the complexities of medical images like X-rays
effectively. In the context of bone fracture detection, CNNs can
automatically learn intricate patterns associated with fractures,
reducing the reliance on manual feature extraction.


\item\textbf{ What is Image Data?}\label{what-is-image-data}

Image data refers to arrays of pixel values that represent visual
information. This data can vary significantly in format, dimensionality,
and complexity depending on the source and intended use. Image data can
be in the form of photographs, medical scans, video sequences, or
satellite images, each presenting unique challenges and opportunities
for processing and analysis.



\paragraph\Large\textbf{Types of Images}\label{types-of-images}

\begin{itemize}
\tightlist
\item
  \textbf{2D Images}: Common in consumer photography and basic machine
  learning applications.
\item
  \textbf{3D Images}: Used in medical imaging and augmented reality for
  providing spatial depth.
\item
  \textbf{Temporal Image Data}: Includes video sequences and is crucial
  for applications requiring motion analysis.
\end{itemize}


\paragraph\Large\textbf{Different Formats}\label{different-formats}

\begin{itemize}
\tightlist
\item
  \textbf{JPEG}: Widely used for its efficient compression.
\item
  \textbf{PNG}: Preferred for its lossless compression.
\item
  \textbf{RAW}: Offers high quality at the cost of larger file sizes,
  often used in professional settings where image manipulation is
  expected.
\end{itemize}

\paragraph\Large\textbf{Characteristics of Image
Data}\label{characteristics-of-image-data}

The characteristics of image data include resolution, color depth, and
dynamic range, each affecting the image's suitability for different
tasks and the preprocessing required. High-resolution images provide
more detail but are computationally expensive to process. Color depth
affects the range of colors that can be represented, and dynamic range
determines the contrast between the darkest and lightest parts of an
image.

\paragraph\Large\label{challenges-with-image-data}

\begin{itemize}
\item
  \textbf{High Dimensionality}: Images can contain millions of pixels,
  leading to high computational complexity.
\item
  \textbf{Noise}: Images often contain noise from sensors or
  environmental factors, which can obscure important features.
\item
  \textbf{Varying Lighting Conditions}: Differences in lighting can
  significantly affect the appearance of features within an image.
\item
  \textbf{Occlusions}: Objects in images can be partially obscured,
  making it difficult to extract relevant features..
\end{itemize}

\paragraph\Large\textbf{Techniques for Image Data}\label{techniques-for-image-data}

\begin{itemize}
\item
  \textbf{Thresholding and Filtering}: Basic techniques to simplify
  images and remove noise.
\item
  \textbf{Contrast Adjustment}: Enhances the visibility of features by
  adjusting the contrast.
\item
  \textbf{Feature Extraction}: Identifies important parts of an image,
  such as edges or textures, using algorithms like Sobel or Canny edge
  detection.
\end{itemize}

\paragraph\Large\textbf{Practical Application
Examples}\label{practical-application-examples}

\begin{itemize}
\tightlist
\item
  \textbf{Medical Imaging}: Enhancing features in X-rays or MRIs for
  better diagnostic accuracy.
\item
  \textbf{Surveillance Systems}: Real-time processing of video data for
  security and monitoring.
\end{itemize}


\item\textbf{ Relevant Literature}\label{relevant-literature}

Research has shown that preprocessing techniques like normalization,
resizing, and data augmentation play a crucial role in improving model
performance. Normalization ensures that the pixel values are consistent,
which speeds up training. Resizing standardizes the input dimensions,
making it easier for models to learn effectively, while data
augmentation increases the diversity of the dataset, enhancing
generalizability. Literature also highlights the importance of combining
machine learning with medical imaging to improve diagnostic accuracy and
efficiency.
\end{itemize}

\section*{\Large\underline{\textbf{Problem Statement}}}\label{references}

\begin{itemize}
     
\item\subsection*{Problem Description}\label{problem-description}

The main problem addressed in this chapter is the automated detection of
bone fractures using X-ray images. Manual examination by radiologists
can be slow and prone to error, especially when the fracture is subtle
or in an unusual location. Thus, automating this process using machine
learning can lead to faster, more reliable diagnoses.

\end{itemize}

\subsection*{Input-Output Definition}\label{input-output-definition}

\begin{itemize}
\item
  \textbf{Input}: Grayscale X-ray images that are resized to a uniform
  dimension of 224x224 pixels.
\item
  \textbf{Output}: A binary classification label indicating whether the
  image shows a ``fractured'' or ``not fractured'' bone.
\end{itemize}

\subsection*{Sample Inputs and Outputs}\label{sample-inputs-and-outputs}

\begin{itemize}
\item
  \textbf{Input Example}: A 224x224 pixel grayscale X-ray image of a
  wrist.
\item
  \textbf{Output Example}: ``Fractured'' (Label: 1).
\end{itemize}

\section*{\Large\underline{\textbf{Problem Analysis}}}\label{references}
\begin{itemize}
    \item\subsection*{Constraints}\label{constraints}
    
\end{itemize}


\begin{itemize}
\item
  \textbf{High Dimensionality}: Images can contain millions of pixels,
  leading to high computational complexity.
\item
  \textbf{Noise}: X-ray images often contain noise from sensors or
  environmental factors, which can obscure important features.
\item
  \textbf{Variability in Image Quality}: X-ray images may vary
  significantly in quality due to different equipment and patient
  positioning.
\item
  \textbf{Varying Lighting Conditions}: Differences in lighting can
  significantly affect the appearance of features within an image.
\end{itemize}

\subsection*{Logic and Approach}\label{logic-and-approach}

The approach involves acquiring X-ray images, preprocessing them to
enhance their quality, and training a CNN model to detect fractures.
Preprocessing steps such as noise reduction, normalization, and data
augmentation are applied to ensure the model can learn effectively.

\subsection*{ Key Principles}\label{key-principles}

\begin{itemize}
\item
  \textbf{Normalization}: Reduces the influence of different lighting
  conditions.
\item
  \textbf{Data Augmentation}: Helps mitigate overfitting by artificially
  increasing the dataset size.
\item
  \textbf{Feature Extraction}: Identifies important parts of an image,
  such as edges or textures, using algorithms like Sobel or Canny edge
  detection.
\item
  \textbf{CNNs}: Automatically learn hierarchical features, making them
  well-suited for tasks involving complex visual data.
\end{itemize}


\section*{\Large\underline{\textbf{Solution Explanation}}}\label{references}

\subsection*{ Well-structured and Easy-to-Follow Solution
Description}\label{well-structured-and-easy-to-follow-solution-description}

The solution involves using Convolutional Neural Networks (CNNs) to
detect bone fractures from X-ray images. The process begins with the
collection and preprocessing of labeled X-ray images categorized as
``fractured'' and ``not fractured.'' The preprocessing includes resizing
images to ensure uniform input size, normalization to improve model
convergence, and data augmentation to enhance variability and prevent
overfitting.

The CNN model was implemented using TensorFlow and Keras, consisting of
convolutional layers for feature extraction, pooling layers to reduce
data dimensionality, and fully connected layers for classification. The
model was trained for 20 epochs using the Adam optimizer and binary
cross-entropy loss. Model evaluation involved accuracy metrics, a
classification report, and confusion matrices to assess its performance
in classifying fractures accurately.

This well-structured approach ensured a step-by-step method of image
acquisition, preprocessing, model building, training, and evaluation,
making it easy to follow and apply.

\subsection*{ Pseudocode or Descriptive Step-by-Step
Solution}\label{pseudocode-or-descriptive-step-by-step-solution}

\subsubsection*{Data Loading:}\label{data-loading}

\begin{itemize}
\tightlist
\item
  Clone the dataset repository from GitHub-
  https://github.com/sanikadhayabar/ADS.git
\item
  Load images dynamically from the specified directory, assigning labels
  based on whether the images are ``fractured'' or ``not fractured.''
\end{itemize}

\subsubsection*{Data Preprocessing:}\label{data-preprocessing}

\begin{itemize}
\tightlist
\item
  Resize images to 224x224 pixels.
\item
  Normalize pixel values to a range between 0 and 1.
\item
  Apply data augmentation techniques such as random rotations,
  translations, and horizontal flipping to increase dataset variability.
\end{itemize}

\subsubsection*{Model Definition:}\label{model-definition}

\begin{itemize}
\tightlist
\item
  Use the Sequential API to build the CNN model with:
\item
  Two convolutional layers followed by max-pooling layers.
\item
  A flattening layer to convert the data into a one-dimensional array.
\item
  Dense layers for classification, with a final sigmoid activation for
  binary classification.
\end{itemize}

\subsubsection*{Model Training:}\label{model-training}

\begin{itemize}
\tightlist
\item
  Compile the model with the Adam optimizer, binary cross-entropy loss,
  and accuracy as the metric.
\item
  Train the model with the augmented image data using an early stopping
  mechanism.
\end{itemize}

\subsubsection*{Model Evaluation:}\label{model-evaluation}

\begin{itemize}
\tightlist
\item
  Evaluate model performance on the test set using a classification
  report and confusion matrix.
\item
  Save the trained model for future use.
\end{itemize}

\subsubsection*{Data Analysis:}\label{data-analysis}

\begin{itemize}
\tightlist
\item
  Predict the test set results and generate a classification report.
\item
  Plot a confusion matrix to visualize model performance in terms of
  true positives, false positives, true negatives, and false negatives.
\end{itemize}

\subsection*{ Logical Reasoning or Proof of
Correctness}\label{logical-reasoning-or-proof-of-correctness}

The CNN architecture was chosen due to its proven effectiveness in
handling image classification tasks, especially in medical imaging.
Convolutional layers automatically learn critical features such as edges
and textures, which are essential for detecting bone fractures. Pooling
layers help in reducing data dimensionality, making the model more
computationally efficient while retaining important features. The use of
fully connected layers and the final sigmoid activation ensures that the
model can effectively classify the images into ``fractured'' or ``not
fractured'' categories.

Data augmentation techniques were employed to address overfitting and
enhance the model's ability to generalize, given the limited dataset
size. The model's performance was evaluated using well-known metrics,
such as accuracy, precision, recall, and F1-score, which provided a
comprehensive overview of how well the model could distinguish between
fractured and not fractured bones. The results indicated that the model
achieved a good level of accuracy, demonstrating the correctness of the
approach in automating fracture detection through deep learning.

\section*{\Large\underline{\textbf{Results and Analysis}}}\label{references}

The results of the bone fracture detection model are supported by
multiple visualizations and code snippets that provide a detailed
understanding of model performance and behavior. Below, we discuss each
of these visual elements:

\textbf{Classification Report}\\
The classification report, as shown in the image, provides essential
performance metrics, such as precision, recall, F1-score, and support
for each class (``fractured'' and ``not fractured''). These metrics
indicate that the model performs well in differentiating between the two
categories, with an overall accuracy of 85\%. The high precision and
recall demonstrate that the model not only captures fractures
effectively but also minimizes false positives.

\textbf{ Confusion Matrix}\\
The confusion matrix visualization illustrates the distribution of true
positives, true negatives, false positives, and false negatives. The
matrix highlights the model's ability to correctly classify the majority
of the ``fractured'' and ``not fractured'' images while also giving
insights into areas for improvement. For instance, the relatively low
number of false positives and false negatives suggests that the model is
learning the distinguishing features effectively, though a few
misclassifications remain. This can guide further tuning and improvement
efforts.

\textbf{ Training and Validation Accuracy/Loss Graphs}\\
The training and validation graphs plot the accuracy and loss across
epochs. As depicted, the model's training accuracy improves steadily
over the epochs, while the validation accuracy also follows a similar
trend without significant divergence. This indicates effective learning
without overfitting, partly due to the use of early stopping and data
augmentation techniques. The decrease in validation loss further
supports the idea that the model generalizes well to unseen data,
suggesting that the CNN architecture and data preprocessing steps were
appropriate for the problem.

The insights from these metrics and visualizations collectively reveal
that the Convolutional Neural Network (CNN) effectively learns key
features from X-ray images for fracture detection. The early stopping
mechanism and data augmentation contribute significantly to the model's
generalization capabilities, preventing overfitting and ensuring
balanced performance across both categories.

The findings support the use of deep learning for medical imaging tasks,
demonstrating significant potential to aid radiologists in providing
more accurate and efficient diagnoses. Going forward, potential
improvements could involve experimenting with more advanced
architectures such as ResNet or VGG, as well as incorporating a larger
and more diverse dataset to further enhance model robustness.

   \section*{\Large\underline{\textbf{References}}}\label{references}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://www.tensorflow.org/}{TensorFlow Documentation}
\item
  \href{https://keras.io/}{Keras Documentation}
\item
  \href{https://www.kaggle.com/datasets}{Kaggle MURA Dataset}
\item
  \href{https://scikit-learn.org/}{scikit-learn}
\item
  \href{https://www.kaggle.com/datasets/ahmedashrafahmed/bone-fracture/data}{Kaggle
  Dataset (Bone Fracture)}
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
